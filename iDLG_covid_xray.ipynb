{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 611,
      "metadata": {
        "id": "0tRnaSEm5GBf"
      },
      "outputs": [],
      "source": [
        "##-- Importing Necessary Libraries --##\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import pickle\n",
        "import PIL.Image as Image\n",
        "from torch.utils.data import DataLoader\n",
        "from path import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 612,
      "metadata": {},
      "outputs": [],
      "source": [
        "##-- Define the Model Class --##\n",
        "class CNN_Model(nn.Module):\n",
        "    def __init__(self, input_shape, hidden_units, output_shape):\n",
        "\n",
        "        super(CNN_Model, self).__init__()\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=input_shape, \n",
        "                out_channels=hidden_units, \n",
        "                kernel_size=5, \n",
        "                padding=5 // 2, # kernel_size/2\n",
        "                stride=2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=hidden_units, \n",
        "                out_channels=hidden_units, \n",
        "                kernel_size=5, \n",
        "                padding=5 // 2, \n",
        "                stride=2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=hidden_units, \n",
        "                out_channels=hidden_units, \n",
        "                kernel_size=5, \n",
        "                padding=5 // 2, \n",
        "                stride=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(\n",
        "                in_features=8*8*hidden_units, \n",
        "                out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 613,
      "metadata": {
        "id": "a1cIx7cs5mxk"
      },
      "outputs": [],
      "source": [
        "##--  Initializes Weights & Biases With Uniform Values in [-0.5, 0.5] --##\n",
        "##-- Sets Initial Random Weights & Biases Before Training Begins --##\n",
        "def weights_init(m):\n",
        "    try:\n",
        "        if hasattr(m, \"weight\"):\n",
        "            m.weight.data.uniform_(-0.5, 0.5)\n",
        "    except Exception:\n",
        "        print('warning: failed in weights_init for %s.weight' % m._get_name())\n",
        "    try:\n",
        "        if hasattr(m, \"bias\"):\n",
        "            m.bias.data.uniform_(-0.5, 0.5)\n",
        "    except Exception:\n",
        "        print('warning: failed in weights_init for %s.bias' % m._get_name())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 614,
      "metadata": {
        "id": "Qr6hLy1k5pSk"
      },
      "outputs": [],
      "source": [
        "##-- PyTorch dataset class that loads images from file paths and applies transformations --##\n",
        "class Dataset_from_Image(Dataset):\n",
        "    def __init__(self, imgs, labs, transform=None):\n",
        "        self.imgs = imgs # img paths\n",
        "        self.labs = labs # labs is ndarray\n",
        "        self.transform = transform\n",
        "        del imgs, labs\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labs.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        lab = self.labs[idx]\n",
        "        img = Image.open(self.imgs[idx])\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        return img, lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 615,
      "metadata": {
        "id": "zoIPNNul5r99"
      },
      "outputs": [],
      "source": [
        "##-- Prepares and returns an image dataset where each image has a corresponding label based on its folder name --##\n",
        "def lfw_dataset(lfw_path, shape_img):\n",
        "    images_all = []\n",
        "    labels_all = []\n",
        "    folders = os.listdir(lfw_path)\n",
        "    for foldidx, fold in enumerate(folders):\n",
        "        files = os.listdir(os.path.join(lfw_path, fold))\n",
        "        for f in files:\n",
        "            if len(f) > 4 and f[-4:] == '.jpg':\n",
        "                images_all.append(os.path.join(lfw_path, fold, f))\n",
        "                labels_all.append(foldidx)\n",
        "\n",
        "    transform = transforms.Compose([transforms.Resize(size=shape_img)])\n",
        "    dst = Dataset_from_Image(images_all, np.asarray(labels_all, dtype=int), transform=transform)\n",
        "    return dst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 616,
      "metadata": {},
      "outputs": [],
      "source": [
        "##-- Setting Up Device Agnostice Code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 617,
      "metadata": {},
      "outputs": [],
      "source": [
        "##-- Define Hyperparameters --##\n",
        "LEARNING_RATE = 0.1\n",
        "NUM_DUMMY = 1 # number of dummy samples used in an experiment\n",
        "ITERATION =5000 # might represent the number of training iterations or optimization steps (not epochs)\n",
        "NUM_EXP = 1 # no of times the experiment is repeated to obtain statistically significant results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 618,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "covid_xray data_path: data/covid_xray\n",
            "covid_xray save_path: results/iDLG_covid_xray\n"
          ]
        }
      ],
      "source": [
        "##-- Define Dataset and Dataset Path & Plots Path --##\n",
        "dataset = 'covid_xray'\n",
        "data_path = Path(\"data/covid_xray\") \n",
        "save_path = Path(\"results/iDLG_covid_xray\")\n",
        "\n",
        "# dataset = 'cifar100'\n",
        "# root_path = '.' \n",
        "# data_path = os.path.join(root_path, './data').replace('\\\\', '/') \n",
        "# save_path = os.path.join(root_path, 'results/iDLG_%s'%dataset).replace('\\\\', '/')\n",
        "\n",
        "print(dataset, 'data_path:', data_path)\n",
        "print(dataset, 'save_path:', save_path)\n",
        "\n",
        "\n",
        "if not os.path.exists('results'): # checks if the results directory exists. if not, creates it.\n",
        "    os.mkdir('results')\n",
        "if not os.path.exists(save_path): # checks if the save_path directory (e.g., './results/iDLG_lfw') exists. if not, creates it.\n",
        "    os.mkdir(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 619,
      "metadata": {},
      "outputs": [],
      "source": [
        "##-- Load Data --##\n",
        "if dataset == 'covid_xray':\n",
        "    shape_img = (32, 32)\n",
        "    num_classes = 3 \n",
        "    in_channels = 3\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),  \n",
        "        transforms.Grayscale(num_output_channels=3)\n",
        "    ])\n",
        "    \n",
        "    dst = datasets.ImageFolder(root=data_path, transform=transform)\n",
        "\n",
        "# elif dataset == 'cifar100':\n",
        "#     shape_img = (32, 32)\n",
        "#     num_classes = 100\n",
        "#     in_channel = 3\n",
        "#     dst = datasets.CIFAR100(root=data_path, \n",
        "#                         download=True,\n",
        "#                         transform = transforms.Compose([\n",
        "#         transforms.Resize((32, 32)),  \n",
        "#         transforms.Grayscale(num_output_channels=3)\n",
        "#     ]))\n",
        "     \n",
        "else:\n",
        "    exit('Unknown Dataset') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 620,
      "metadata": {
        "id": "WBxAAYGI577Q"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "    tt = transforms.Compose([transforms.ToTensor()])\n",
        "    tp = transforms.Compose([transforms.ToPILImage()]) # converts a tensor back into a PIL image\n",
        "\n",
        "    ##-- Train DLG and iDLG --##\n",
        "    for idx_net in range(NUM_EXP):\n",
        "        model = CNN_Model(input_shape=in_channels, hidden_units=12, output_shape=num_classes)\n",
        "        model.apply(weights_init) # apply custom weight initialization\n",
        "\n",
        "        print(f\"Running {idx_net}|{NUM_EXP} Experiment\")\n",
        "        model = model.to(device)\n",
        "        idx_shuffle = np.random.permutation(len(dst)) # shuffles the indices of the dataset dst randomly [list].\n",
        "\n",
        "        print(f\"\\niDLG, Try to generate {NUM_DUMMY} images\")\n",
        "\n",
        "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "        idx_list = []\n",
        "\n",
        "        for imidx in range(NUM_DUMMY): # iterates NUM_DUMMY times, where each iteration selects one random sample from dst\n",
        "            idx = idx_shuffle[imidx] # retrieves a randomly shuffled index from idx_shuffle\n",
        "            idx_list.append(idx) # saves the selected index (idx) in idx_list, possibly for tracking or debugging.\n",
        "            tmp_datum = tt(dst[idx][0]).float().to(device) # extracts the data sample from dst at index idx & applies tt(...), likely a transformation function\n",
        "            tmp_datum = tmp_datum.view(1, *tmp_datum.size()) # Shape: (1, C, H, W)\n",
        "            tmp_label = torch.Tensor([dst[idx][1]]).long().to(device) # extracts the label from dst at index `idx`.\n",
        "            tmp_label = tmp_label.view(1, ) # reshapes tmp_label into a 1D tensor with one element (shape: (1,)).\n",
        "            if imidx == 0:\n",
        "                # first sample (tmp_datum, tmp_label) is directly assigned\n",
        "                gt_data = tmp_datum\n",
        "                gt_label = tmp_label\n",
        "            else:\n",
        "                # torch.cat() appends tmp_datum and tmp_label along dim=0, forming a growing batch\n",
        "                gt_data = torch.cat((gt_data, tmp_datum), dim=0)\n",
        "                gt_label = torch.cat((gt_label, tmp_label), dim=0)\n",
        "\n",
        "\n",
        "            ##-- Compute Original Gradient --##\n",
        "            out = model(gt_data) # passes the batch gt_data through the model & out contains the modelâ€™s raw outputs (logits for classification)\n",
        "            y = loss_fn(out, gt_label) # computes the loss between out (model predictions) and gt_label (true labels).\n",
        "            dy_dx = torch.autograd.grad(y, model.parameters()) # computes gradients of the loss (y) wrt model parameters (w and b). \n",
        "                # dy_dx is a list of gradients for each parameter in the model.\n",
        "            original_dy_dx = list((_.detach().clone() for _ in dy_dx)) \n",
        "                # detaches each gradient from the computation graph to prevent unwanted autograd tracking.\n",
        "                # clones the detached gradients to store an independent copy (original_dy_dx).\n",
        "                # ensures original_dy_dx remains unchanged even if future operations modify dy_dx.\n",
        "\n",
        "            ##-- Generate Dummy Data and Label --##\n",
        "            dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
        "            dummy_label = torch.randn((gt_data.shape[0], num_classes)).to(device).requires_grad_(True)\n",
        "\n",
        "            # if (iDLG) is used, only dummy_data is optimized (label is inferred separately).\n",
        "            optimizer = torch.optim.LBFGS([dummy_data, ], lr=LEARNING_RATE)\n",
        "            ##-- Predict Ground-Truth Label --##\n",
        "            # dim=1 specifies the axis along which an operation is applied.\n",
        "            label_pred = torch.argmin(torch.sum(original_dy_dx[-2], dim=-1), dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
        "\n",
        "            history = []\n",
        "            history_iters = []\n",
        "            losses = []\n",
        "            mses = []\n",
        "            train_iters = []\n",
        "\n",
        "            print('lr =', LEARNING_RATE)\n",
        "            for iters in range(ITERATION):\n",
        "\n",
        "                ##-- Computes the gradient difference between dummy and original gradients and updates dummy_data accordingly --##\n",
        "                def closure():\n",
        "                    optimizer.zero_grad() # clears previously accumulated gradients before computing new ones\n",
        "                    pred = model(dummy_data) # feeds the dummy data into the model to get predictions\n",
        "\n",
        "                    dummy_loss = loss_fn(pred, label_pred) # in iDLG, the loss is computed against label_pred, which was inferred earlier\n",
        "\n",
        "                    dummy_dy_dx = torch.autograd.grad(dummy_loss, model.parameters(), create_graph=True) # computes gradients of dummy_loss w.r.t. model parameters\n",
        "\n",
        "                    grad_diff = 0\n",
        "                    for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
        "                        grad_diff += ((gx - gy) ** 2).sum() # accumulates the total gradient mismatch (grad_diff).\n",
        "                    grad_diff.backward() # computes gradients of grad_diff w.r.t. dummy_data, allowing LBFGS to update dummy data\n",
        "                    return grad_diff\n",
        "                    # This closure() function is called repeatedly by LBFGS optimizer to refine dummy_data\n",
        "\n",
        "                ##-- This is part of an LBFGS optimization loop to reconstruct data from gradients in DLG/iDLG. --##\n",
        "                optimizer.step(closure) # optimizes dummy_data so that its gradients match the original gradients.\n",
        "                current_loss = closure().item() # computes current gradient difference loss (grad_diff) & .item() extracts the scalar loss value\n",
        "                train_iters.append(iters) # stores the current iteration count for visualization or analysis later.\n",
        "                losses.append(current_loss) # appends current_loss to losses list to track progress.\n",
        "                mses.append(torch.mean((dummy_data-gt_data)**2).item()) # (MSE) between the reconstructed dummy_data and original gt_data\n",
        "\n",
        "\n",
        "                if iters % int(ITERATION / 50) == 0:\n",
        "                    current_time = str(time.strftime(\"[%Y-%m-%d %H:%M:%S]\", time.localtime()))\n",
        "                    print(current_time, iters, 'loss = %.8f, mse = %.8f' %(current_loss, mses[-1]))\n",
        "                    history.append([tp(dummy_data[imidx].cpu()) for imidx in range(NUM_DUMMY)])\n",
        "                    history_iters.append(iters)\n",
        "\n",
        "                    for imidx in range(NUM_DUMMY):\n",
        "                        plt.figure(figsize=(15, 8))\n",
        "\n",
        "                        plt.subplot(5, 10, 1)\n",
        "                        plt.imshow(tp(gt_data[imidx].cpu())) # show original image\n",
        "                        plt.title(\"original\")\n",
        "                        plt.axis(False)\n",
        "\n",
        "                        for i in range(min(len(history), 48)):  # ensure i + 2 does not exceed 60\n",
        "                            plt.subplot(5, 10, i + 2)\n",
        "                            plt.imshow(history[i][imidx])\n",
        "                            plt.title(f\"iter={history_iters[i]}\")\n",
        "                            plt.axis(False)\n",
        "\n",
        "                        plt.savefig('%s/iDLG_on_%s_%05d.png' % (save_path, idx_list, idx_list[imidx]))\n",
        "                        plt.close()\n",
        "\n",
        "                    if current_loss < 0.000001: # converge\n",
        "                        break\n",
        "\n",
        "            loss_iDLG = losses\n",
        "            label_iDLG = label_pred.item()\n",
        "            mse_iDLG = mses\n",
        "\n",
        "\n",
        "        print('idx_list:', idx_list)\n",
        "        print('loss_iDLG:', loss_iDLG[-1])\n",
        "        print('mse_iDLG:', mse_iDLG[-1])\n",
        "        print('gt_label:', gt_label.detach().cpu().data.numpy(),'lab_iDLG:', label_iDLG)\n",
        "\n",
        "        print('--------------------------------------------\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 621,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVB8jws75uNf",
        "outputId": "4023c031-bb6e-4bf7-d8e9-bd5cb98fac27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running 0|1 Experiment\n",
            "\n",
            "iDLG, Try to generate 1 images\n",
            "lr = 0.1\n",
            "[2025-03-26 02:29:45] 0 loss = 105.90216827, mse = 1.12503135\n",
            "[2025-03-26 02:29:53] 100 loss = 0.00022188, mse = 0.00130259\n",
            "[2025-03-26 02:30:04] 200 loss = 0.00000154, mse = 0.00000795\n",
            "[2025-03-26 02:30:06] 300 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:07] 400 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:07] 500 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:08] 600 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:09] 700 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:10] 800 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:11] 900 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:11] 1000 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:13] 1100 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:15] 1200 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:15] 1300 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:16] 1400 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:18] 1500 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:19] 1600 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:20] 1700 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:21] 1800 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:23] 1900 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:24] 2000 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:25] 2100 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:26] 2200 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:26] 2300 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:28] 2400 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:29] 2500 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:31] 2600 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:32] 2700 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:34] 2800 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:35] 2900 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:36] 3000 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:37] 3100 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:38] 3200 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:39] 3300 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:40] 3400 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:41] 3500 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:42] 3600 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:43] 3700 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:44] 3800 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:46] 3900 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:47] 4000 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:48] 4100 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:49] 4200 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:50] 4300 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:51] 4400 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:52] 4500 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:53] 4600 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:54] 4700 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:55] 4800 loss = 0.00000153, mse = 0.00000787\n",
            "[2025-03-26 02:30:56] 4900 loss = 0.00000153, mse = 0.00000787\n",
            "idx_list: [np.int64(5646)]\n",
            "loss_iDLG: 1.5304671023841365e-06\n",
            "mse_iDLG: 7.869965884310659e-06\n",
            "gt_label: [1] lab_iDLG: 1\n",
            "--------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
